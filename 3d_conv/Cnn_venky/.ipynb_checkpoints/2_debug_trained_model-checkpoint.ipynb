{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Ice-Cube 3D CNN\n",
    "\n",
    "- Oct 29, 2018: This code just makes plots for previously trained CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful blog for keras conv3D: http://learnandshare645.blogspot.com/2016/06/3d-cnn-in-keras-action-recognition.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras modules\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks  # or tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from tensorflow.keras.models import load_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "### Modules for viewing predicted data ###\n",
    "def f_plt_hist(ypred):\n",
    "    ''' Plot a histogram of predictions'''\n",
    "    print(ypred.shape)\n",
    "    plt.figure()\n",
    "    n,bins,patches=plt.hist(ypred, density=None, bins=300)\n",
    "    plt.xlim(0,1)\n",
    "    plt.show()\n",
    "#     plt.close()\n",
    "\n",
    "def f_get_prediction_info(y_pred,plot=False):\n",
    "    ''' Function that prints info on predicted data.\n",
    "        For example, number of zeroes and ones, plots, etc.\n",
    "    '''\n",
    "    \n",
    "    # Condition for the case when the prediction is a 2 column array \n",
    "    arr=y_pred[:,1] if len(y_pred.shape)==2 else y_pred\n",
    "    \n",
    "    # Print info and plot\n",
    "    num_total=arr.shape[0]\n",
    "    num_zeros=arr[arr==0.0].shape[0]\n",
    "    num_ones=arr[arr==1.0].shape[0]\n",
    "    print(\"Pred 0's:\\t%s,\\tPred 1's:\\t%s,Total:\\t %s\" %(num_zeros,num_ones,num_total))\n",
    "    if plot:\n",
    "        ### Plot histogram ###\n",
    "        f_plt_hist(arr)\n",
    "\n",
    "\n",
    "def f_get_ydata_and_wts(data_dir,f1,f2):\n",
    "    ''' Load extracted data from files. Just extracting ydata and weights\n",
    "    returns : inpy,weights as arrays\n",
    "    '''\n",
    "\n",
    "    inpy=np.loadtxt(data_dir+f1)\n",
    "    wts=np.loadtxt(data_dir+f2)\n",
    "    \n",
    "    return inpy,wts\n",
    "    \n",
    "def f_plot_learning(history):\n",
    "    '''Plot learning curves : Accuracy and Validation'''\n",
    "    fig=plt.figure()\n",
    "    # Plot training & validation accuracy values\n",
    "    fig.add_subplot(2,1,1)\n",
    "    xlim=len(history['acc'])\n",
    "    \n",
    "    plt.plot(history['acc'],label='Train',marker='o')\n",
    "    plt.plot(history['val_acc'],label='Validation',marker='*')\n",
    "#     plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(np.arange(0,xlim,2))\n",
    "    \n",
    "    # Plot loss values\n",
    "    fig.add_subplot(2,1,2)\n",
    "    plt.plot(history['loss'],label='Train',marker='o')\n",
    "    plt.plot(history['val_loss'],label='Validation',marker='*')\n",
    "#     plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.xticks(np.arange(0,xlim,2))\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "\n",
    "def f_plot_roc_curve(fpr,tpr):\n",
    "    '''\n",
    "    Module for roc plot and printing AUC\n",
    "    '''\n",
    "    plt.figure()\n",
    "    # plt.plot(fpr,tpr)\n",
    "#     plt.scatter(fpr,tpr)\n",
    "    plt.semilogx(fpr, tpr)\n",
    "  # Zooms\n",
    "    plt.xlim([10**-7,1.0])\n",
    "    plt.ylim([0,1.0])\n",
    "    # y=x line for comparison\n",
    "    x=np.linspace(0,1,num=500)\n",
    "    plt.plot(x,x)\n",
    "#     plt.xscale('log')\n",
    "#     plt.xlim(1e-10,1e-5)\n",
    "    plt.show()\n",
    "\n",
    "    # AUC \n",
    "    auc_val = auc(fpr, tpr)\n",
    "    print(\"AUC: \",auc_val)\n",
    "\n",
    "\n",
    "def f_plot_fit(inpy,wts,model_dict,model_loc,plt_roc=True,plt_learning=True,model_desc=True,plt_pred=True):\n",
    "    '''\n",
    "    Plot fit results.\n",
    "    Steps:\n",
    "    - Read model from .h5 files\n",
    "    - Describle model structure\n",
    "    - Plot learning history\n",
    "    - Read predictions from previous test\n",
    "    - Get prediction information: number of zeros and ones. Plot of histogram.\n",
    "    - Roc curve: Compute and plot roc curve. Store results in dictionary.\n",
    "    '''\n",
    "    \n",
    "    model_save_dir=model_loc\n",
    "    model_name=model_dict['name'] # string for the model\n",
    "    fname_model,fname_history='model_{0}.h5'.format(model_name),'history_{0}.pickle'.format(model_name)\n",
    "    \n",
    "        \n",
    "    ########################\n",
    "    ## Read model and history\n",
    "    \n",
    "    ### Check if files exist\n",
    "    assert os.path.exists(model_save_dir+fname_model),\"Model not saved\"\n",
    "    assert os.path.exists(model_save_dir+fname_history),\"History not saved\"\n",
    "    \n",
    "    model=load_model(model_save_dir+fname_model)\n",
    "    with open(model_save_dir+fname_history,'rb') as f:\n",
    "        history= pickle.load(f)\n",
    "    \n",
    "    ########################\n",
    "    if model_desc: model.summary()\n",
    "    # Plot learning of trained model\n",
    "    if plt_learning: f_plot_learning(history)\n",
    "    \n",
    "    ########################\n",
    "    # Get test predictions\n",
    "    \n",
    "    test_file_name=model_save_dir+'y-predict_model-'+str(model_name)+'.pred'\n",
    "    test_y_file_name=model_save_dir+'y-test_model-'+str(model_name)+'.test'\n",
    "    test_weights_file_name=model_save_dir+'wts-test_model-'+str(model_name)+'.test'    \n",
    "    print(\"Using test prediction from previous test\",test_file_name)\n",
    "\n",
    "    assert os.path.exists(test_file_name),\"y-predictions not saved\"\n",
    "    y_pred=np.loadtxt(test_file_name)\n",
    "    ydata=np.loadtxt(test_y_file_name)\n",
    "    wts=np.loadtxt(test_weights_file_name)\n",
    "    assert(test_y.shape[0]==y_pred.shape[0]),\"Data %s and prediction arrays %s are not of the same size\"%(test_y.shape,y_pred.shape)\n",
    "    \n",
    "    # Condition for the case when the prediction is a 2column array \n",
    "    if len(y_pred.shape)==2: y_pred=y_pred[:,1]\n",
    "    \n",
    "    ## Prints details of predictions\n",
    "    f_get_prediction_info(y_pred,plot=plt_pred)\n",
    "    \n",
    "    fpr,tpr,threshold=roc_curve(ydata,y_pred,sample_weight=wts)\n",
    "    model_dict['fpr'], model_dict['tpr'], model_dict['threshold']=fpr,tpr,threshold\n",
    "    print(fpr.shape,tpr.shape,threshold.shape)\n",
    "    if plt_roc: f_plot_roc_curve(fpr,tpr)\n",
    "    \n",
    "    model_dict['model'],model_dict['history']=model,history\n",
    "    \n",
    "    return model_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read part of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    \n",
    "    model_loc='/global/project/projectdirs/dasrepo/vpa/ice_cube/data_for_cnn/results_data/final_7models_march17_2019/'\n",
    "    ###Extract data : Only extract y-data and weights for tests, which has been saved already along with the model.\n",
    "    ### Note!: the test file data is the same for all models, so just pick the first one. ###\n",
    "    f1,f2='y-test_model-1.test','wts-test_model-1.test'\n",
    "#     f1,f2='y-test_model-15.test','wts-test_model-15.test'\n",
    "\n",
    "    inpy,wts=f_get_ydata_and_wts(model_loc,f1,f2)\n",
    "    test_y,test_wts=inpy[:],wts[:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368857,) (368857,) (368857,) (368857,)\n"
     ]
    }
   ],
   "source": [
    "print(inpy.shape,wts.shape,test_y.shape,test_wts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Plot fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'name': '1', 'description': None, 'model': None, 'history': None, 'fpr': None, 'tpr': None, 'threshold': None}\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10, 20, 60, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 10, 20, 60, 10)    280       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 5, 10, 30, 10)     0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 10, 30, 10)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 5, 10, 30, 10)     2710      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 2, 5, 15, 10)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 5, 15, 10)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 2, 5, 15, 10)      2710      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 1, 2, 7, 10)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 2, 7, 10)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                9024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 14,789\n",
      "Trainable params: 14,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38f315ae5c9458d80160fb4f0c639bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using test prediction from previous test /global/project/projectdirs/dasrepo/vpa/ice_cube/data_for_cnn/results_data/final_7models_march17_2019/y-predict_model-1.pred\n",
      "Pred 0's:\t2,\tPred 1's:\t34,Total:\t 368857\n",
      "(368857,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a0a34c40fa42a2a9f7c4e1ee98c9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(363142,) (363142,) (363142,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678e761c33744523b876f0a562018862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9214806038496348\n",
      "4 {'name': '4', 'description': None, 'model': None, 'history': None, 'fpr': None, 'tpr': None, 'threshold': None}\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 10, 20, 60, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 10, 20, 60, 40)    3880      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 10, 20, 60, 40)    160       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 10, 10, 20, 40)    0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 10, 10, 20, 40)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 10, 10, 20, 40)    153640    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10, 10, 20, 40)    160       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 10, 5, 6, 40)      0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 10, 5, 6, 40)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 10, 5, 6, 40)      153640    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 5, 6, 40)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 10, 2, 2, 40)      0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 10, 2, 2, 40)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 10, 2, 2, 80)      307280    \n",
      "_________________________________________________________________\n",
      "conv3d_13 (Conv3D)           (None, 10, 2, 2, 120)     921720    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4800)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 120)               576120    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 121       \n",
      "=================================================================\n",
      "Total params: 2,116,881\n",
      "Trainable params: 2,116,641\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8affba3e26c74027a27f3a6095602af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using test prediction from previous test /global/project/projectdirs/dasrepo/vpa/ice_cube/data_for_cnn/results_data/final_7models_march17_2019/y-predict_model-4.pred\n",
      "Pred 0's:\t0,\tPred 1's:\t50,Total:\t 368857\n",
      "(368857,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f29789edf6e4e539c9ec8185a3f8a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(365936,) (365936,) (365936,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb33bc9a14ae48228944b81fdc5e4213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9596425513880648\n"
     ]
    }
   ],
   "source": [
    "dict_list=[]\n",
    "# for i in range(1,16):\n",
    "for i in [1,4]:\n",
    "    model_dict=dict.fromkeys(['name','description','model','history','fpr','tpr','threshold'],None)\n",
    "    model_dict['name']=str(i)\n",
    "    print(i,model_dict)\n",
    "    model_dict=f_plot_fit(test_y,test_wts,model_dict,model_loc,plt_roc=True,plt_learning=True,model_desc=True,plt_pred=True)\n",
    "    dict_list.append(model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f2c8de07de4025b216d6f2e8738114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "def f_plot_roc_curve_all(model_dict):\n",
    "    '''\n",
    "    Module for roc plot and printing AUC\n",
    "    '''\n",
    "    \n",
    "    fpr,tpr=model_dict['fpr'],model_dict['tpr']\n",
    "    auc_val = auc(fpr, tpr)\n",
    "\n",
    "#     plt.scatter(fpr,tpr,marker='o',label='Model='+str(model_dict['name'])+\"\\nAUC: \"+str(auc_val))\n",
    "    plt.plot(fpr,tpr,label='Model='+str(model_dict['name'])+\"\\nAUC: \"+str(auc_val))\n",
    "    plt.xscale('log')\n",
    "  # Zooms\n",
    "    plt.xlim([10**-8,1.0])\n",
    "    plt.ylim([0,1.0])\n",
    "    ### Plot Physics benchmark point\n",
    "#   ##Physics benchmark [1.44576*10**-6 FPR, 0.04302 TPR]\n",
    "    phys_x,phys_y=1.44576*10**-6,0.04302\n",
    "    plt.scatter(phys_x,phys_y,color='red')\n",
    "#     plt.xscale('log')\n",
    "#     plt.xlim(1e-10,1e-5)\n",
    "#     plt.show()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"False postive rate (1- Background rejection)\")\n",
    "    plt.ylabel(\"True postive rate (Signal Efficiency)\")\n",
    "plt.figure()\n",
    "# f_plot_roc_curve_all(model)\n",
    "for i in dict_list:\n",
    "    if int(i['name']) in [1,3,7]:\n",
    "        print(i['name'])\n",
    "        f_plot_roc_curve_all(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interact(f_text_plot, a=RadioButtons(\n",
    "#     options=['1','2','3'],\n",
    "#     value='3',\n",
    "#     description='Plot type:',\n",
    "#     disabled=False\n",
    "# ));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "v_py3",
   "language": "python",
   "name": "v_jpt_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
