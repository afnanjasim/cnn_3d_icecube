{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Ice-Cube 3D CNN\n",
    "Using Wahid's tutorial keras code on ICE-Cube CNN data.\n",
    "- October 5, 2018: 2D CNN works.\n",
    "- October 6, 2018: got simple 3D CNN to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from load_data.ipynb\n",
      "importing Jupyter notebook from util.ipynb\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nbfinder import NotebookFinder\n",
    "import sys\n",
    "import os\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from load_data import get_data\n",
    "\n",
    "# import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# %matplotlib notebook\n",
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful blog for keras conv3D: http://learnandshare645.blogspot.com/2016/06/3d-cnn-in-keras-action-recognition.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_plot.py   load_data.ipynb  my_code.ipynb  nbfinder.pyc       rpv_weights.h5\n",
      "\u001b[0m\u001b[01;34m__pycache__\u001b[0m/  main.ipynb       nbfinder.py    resnet_util.ipynb  util.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# keras modules\n",
    "import keras\n",
    "from keras import layers, models, optimizers, callbacks  # or tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# from keras.layers import *\n",
    "# from keras.models import Model,Sequential\n",
    "# from keras.optimizers import adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from resnet_util.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Import modules form other nbs\n",
    "from resnet_util import identity_block,conv_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys; sys.executable\n",
    "# print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigpath = \"/project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/\"\n",
    "sig_list=glob.glob(sigpath+'*00.hdf5')\n",
    "bgpath = \"/project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/corsika/11057/\"\n",
    "bg_list=glob.glob(bgpath+'*00.hdf5')\n",
    "\n",
    "inx,iny = get_data(sig_list, bg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1388, 60, 10, 20)\n",
      "(1388,)\n",
      "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 1.0)\n"
     ]
    }
   ],
   "source": [
    "print(inx.shape)\n",
    "print(iny.shape)\n",
    "print(inx[0,0,:,0],iny[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(iny[:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1388\n"
     ]
    }
   ],
   "source": [
    "print(inx.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and cross-validation inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1388, 1, 60, 10, 20), (1388, 10, 20, 60, 1))\n",
      "((694, 10, 20, 60, 1), (694,))\n",
      "((694, 10, 20, 60, 1), (694,))\n"
     ]
    }
   ],
   "source": [
    "inx2=np.expand_dims(inx,axis=1)\n",
    "inx3=np.transpose(inx2,axes=[0,3,4,2,1])\n",
    "print(inx2.shape,inx3.shape)\n",
    "\n",
    "inpx=inx3.copy()\n",
    "inpy=iny.copy()\n",
    "\n",
    "num=(inpx.shape[0])\n",
    "cval_prop=0.5\n",
    "cv_index=int(cval_prop*num)\n",
    "train_x,train_y=inpx[:cv_index],inpy[:cv_index]\n",
    "cval_x,cval_y=inpx[cv_index:],inpy[cv_index:]\n",
    "\n",
    "print(train_x.shape,train_y.shape)\n",
    "print(cval_x.shape,cval_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Conv2D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # making a 2D conv array for testing purposes\n",
    "# inx4=inx3[:,[2,3,4]]\n",
    "# inx4=inx3[:,0,:,:,:]\n",
    "# print(inx4.shape)\n",
    "# iny.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = layers.Input(shape=inx4.shape[1:])\n",
    "# h = inputs\n",
    "\n",
    "# # Convolutional layers\n",
    "# conv_sizes=[64, 128, 256]\n",
    "# conv_args = dict(kernel_size=(3, 3), activation='relu', padding='same')\n",
    "# for conv_size in conv_sizes:\n",
    "#     h = layers.Conv2D(conv_size, **conv_args)(h)\n",
    "#     h = layers.MaxPooling2D(pool_size=(2, 2))(h)\n",
    "# #h = layers.Dropout(0.5)(h)\n",
    "# h = layers.Flatten()(h)\n",
    "\n",
    "# # Fully connected  layers\n",
    "# h = layers.Dense(64, activation='relu')(h)\n",
    "# #    h = layers.Dropout(0.5)(h)\n",
    "\n",
    "# # Ouptut layer\n",
    "# outputs = layers.Dense(1, activation='sigmoid')(h)\n",
    "\n",
    "\n",
    "# model = models.Model(inputs, outputs)\n",
    "# model.compile(optimizer=optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "- model.fit \n",
    "    - batch_size= sample of data used for training (subset of full training set). \n",
    "    - epoch= number of runs over training data\n",
    "    - callbacks=\n",
    "    \n",
    "- for layers.Input need size (x,y,z,1) in channels_last mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x=inx4, y=iny,\n",
    "#                       batch_size=128,\n",
    "#                       epochs=3,\n",
    "#                       verbose=1,\n",
    "#                       callbacks = [\n",
    "#                         callbacks.ModelCheckpoint('./rpv_weights.h5')\n",
    "#                       ],                      \n",
    "#                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To figure out:\n",
    "- model.fit(callbacks= ...)\n",
    "- model.predict \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=train_x.shape[1:])\n",
    "h = inputs\n",
    "\n",
    "# Convolutional layers\n",
    "conv_sizes=[64, 128, 256]\n",
    "conv_args = dict(kernel_size=(3, 3, 3), activation='relu', padding='same')\n",
    "for conv_size in conv_sizes:\n",
    "    h = layers.Conv3D(conv_size, **conv_args)(h)\n",
    "    h = layers.MaxPooling3D(pool_size=(2, 2, 2))(h)\n",
    "#h = layers.Dropout(0.5)(h)\n",
    "h = layers.Flatten()(h)\n",
    "\n",
    "# Fully connected  layers\n",
    "h = layers.Dense(64, activation='relu')(h)\n",
    "#    h = layers.Dropout(0.5)(h)\n",
    "\n",
    "# Ouptut layer\n",
    "outputs = layers.Dense(1, activation='sigmoid')(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model(inputs, outputs)\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "694/694 [==============================] - 124s 178ms/step - loss: 5.7071 - acc: 0.6225\n",
      "Epoch 2/3\n",
      "694/694 [==============================] - 101s 146ms/step - loss: 5.8062 - acc: 0.6398\n",
      "Epoch 3/3\n",
      "694/694 [==============================] - 60s 87ms/step - loss: 5.8062 - acc: 0.6398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b5685d6ef90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_x, y=train_y,\n",
    "                      batch_size=32,\n",
    "                      epochs=3,\n",
    "                      verbose=1,\n",
    "                      callbacks = [\n",
    "                        callbacks.ModelCheckpoint('./rpv_weights.h5')\n",
    "                      ],                      \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10, 20, 60, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 10, 20, 60, 64)    1792      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 5, 10, 30, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 5, 10, 30, 128)    221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 2, 5, 15, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 2, 5, 15, 256)     884992    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 1, 2, 7, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3584)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                229440    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,337,601\n",
      "Trainable params: 1,337,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694/694 [==============================] - 55s 79ms/step\n",
      "Validation Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(cval_x,  cval_y); print (\"Validation Accuracy: \" + str(score[1] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694/694 [==============================] - 29s 42ms/step\n",
      "Test Accuracy: 0.6397694524495677\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(train_x,  train_y); print (\"Test Accuracy: \" + str(score[1] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000001515422036e-07, 1.0]\n",
      "694/694 [==============================] - 54s 78ms/step\n"
     ]
    }
   ],
   "source": [
    "print(score)\n",
    "prd=model.predict(cval_x,verbose=1)\n",
    "# print(prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (694, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prd),prd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((694, 1), (0,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd.shape,prd[prd>0.0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting cv results\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(cval_y,color='r',marker='H')\n",
    "plt.plot(prd,color='b',linestyle='',marker='*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_inbound_node',\n",
       " '_base_init',\n",
       " '_built',\n",
       " '_check_trainable_weights_consistency',\n",
       " '_collected_trainable_weights',\n",
       " '_compute_previous_mask',\n",
       " '_expects_training_arg',\n",
       " '_feed_input_names',\n",
       " '_feed_input_shapes',\n",
       " '_feed_inputs',\n",
       " '_feed_loss_fns',\n",
       " '_feed_output_names',\n",
       " '_feed_output_shapes',\n",
       " '_feed_outputs',\n",
       " '_feed_sample_weight_modes',\n",
       " '_feed_sample_weights',\n",
       " '_feed_targets',\n",
       " '_function_kwargs',\n",
       " '_get_node_attribute_at_index',\n",
       " '_inbound_nodes',\n",
       " '_init_graph_network',\n",
       " '_init_subclassed_network',\n",
       " '_initial_weights',\n",
       " '_input_coordinates',\n",
       " '_input_layers',\n",
       " '_is_compiled',\n",
       " '_is_graph_network',\n",
       " '_layers',\n",
       " '_layers_by_depth',\n",
       " '_losses',\n",
       " '_make_predict_function',\n",
       " '_make_test_function',\n",
       " '_make_train_function',\n",
       " '_network_nodes',\n",
       " '_node_key',\n",
       " '_nodes_by_depth',\n",
       " '_outbound_nodes',\n",
       " '_output_coordinates',\n",
       " '_output_layers',\n",
       " '_output_mask_cache',\n",
       " '_output_shape_cache',\n",
       " '_output_tensor_cache',\n",
       " '_per_input_losses',\n",
       " '_per_input_updates',\n",
       " '_set_inputs',\n",
       " '_standardize_user_data',\n",
       " '_updated_config',\n",
       " '_updates',\n",
       " '_uses_dynamic_learning_phase',\n",
       " '_uses_inputs_arg',\n",
       " 'add_loss',\n",
       " 'add_update',\n",
       " 'add_weight',\n",
       " 'assert_input_compatibility',\n",
       " 'build',\n",
       " 'built',\n",
       " 'call',\n",
       " 'compile',\n",
       " 'compute_mask',\n",
       " 'compute_output_shape',\n",
       " 'count_params',\n",
       " 'evaluate',\n",
       " 'evaluate_generator',\n",
       " 'fit',\n",
       " 'fit_generator',\n",
       " 'from_config',\n",
       " 'get_config',\n",
       " 'get_input_at',\n",
       " 'get_input_mask_at',\n",
       " 'get_input_shape_at',\n",
       " 'get_layer',\n",
       " 'get_losses_for',\n",
       " 'get_output_at',\n",
       " 'get_output_mask_at',\n",
       " 'get_output_shape_at',\n",
       " 'get_updates_for',\n",
       " 'get_weights',\n",
       " 'history',\n",
       " 'input',\n",
       " 'input_mask',\n",
       " 'input_names',\n",
       " 'input_shape',\n",
       " 'input_spec',\n",
       " 'inputs',\n",
       " 'layers',\n",
       " 'load_weights',\n",
       " 'loss',\n",
       " 'loss_functions',\n",
       " 'loss_weights',\n",
       " 'losses',\n",
       " 'metrics',\n",
       " 'metrics_names',\n",
       " 'metrics_tensors',\n",
       " 'metrics_updates',\n",
       " 'name',\n",
       " 'non_trainable_weights',\n",
       " 'optimizer',\n",
       " 'output',\n",
       " 'output_mask',\n",
       " 'output_names',\n",
       " 'output_shape',\n",
       " 'outputs',\n",
       " 'predict',\n",
       " 'predict_function',\n",
       " 'predict_generator',\n",
       " 'predict_on_batch',\n",
       " 'reset_states',\n",
       " 'run_internal_graph',\n",
       " 'sample_weight_mode',\n",
       " 'sample_weight_modes',\n",
       " 'sample_weights',\n",
       " 'save',\n",
       " 'save_weights',\n",
       " 'set_weights',\n",
       " 'state_updates',\n",
       " 'stateful',\n",
       " 'stateful_metric_functions',\n",
       " 'stateful_metric_names',\n",
       " 'stop_training',\n",
       " 'summary',\n",
       " 'supports_masking',\n",
       " 'targets',\n",
       " 'test_function',\n",
       " 'test_on_batch',\n",
       " 'to_json',\n",
       " 'to_yaml',\n",
       " 'total_loss',\n",
       " 'train_function',\n",
       " 'train_on_batch',\n",
       " 'trainable',\n",
       " 'trainable_weights',\n",
       " 'updates',\n",
       " 'uses_learning_phase',\n",
       " 'weighted_metrics',\n",
       " 'weights']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old code from Zahra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.show()\n",
    "\n",
    "# # plt.savefig('lossresnetgpu3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### notes:\n",
    "- shuffle data\n",
    "- weighted rock curve (curve in the plot).\n",
    "- Result on Monday!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "v_python2",
   "language": "python",
   "name": "v_jpt_py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
