{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Ice-Cube 3D CNN\n",
    "\n",
    "- Oct 29, 2018: This code just makes plots for previously trained CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful blog for keras conv3D: http://learnandshare645.blogspot.com/2016/06/3d-cnn-in-keras-action-recognition.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras modules\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks  # or tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from tensorflow.keras.models import load_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_get_ydata_and_wts(data_dir,f1,f2):\n",
    "    ''' Load extracted data from files. Just extracting ydata and weights\n",
    "    returns : inpy,weights as arrays\n",
    "    '''\n",
    "\n",
    "    inpy=np.loadtxt(data_dir+f1)\n",
    "    wts=np.loadtxt(data_dir+f2)\n",
    "    \n",
    "    return inpy,wts\n",
    "    \n",
    "def f_plot_learning(history):\n",
    "    '''Plot learning curves : Accuracy and Validation'''\n",
    "    fig=plt.figure()\n",
    "    # Plot training & validation accuracy values\n",
    "    fig.add_subplot(2,1,1)\n",
    "    xlim=len(history['acc'])\n",
    "    \n",
    "    plt.plot(history['acc'],label='Train',marker='o')\n",
    "    plt.plot(history['val_acc'],label='Validation',marker='*')\n",
    "#     plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(np.arange(0,xlim,2))\n",
    "    \n",
    "    # Plot loss values\n",
    "    fig.add_subplot(2,1,2)\n",
    "    plt.plot(history['loss'],label='Train',marker='o')\n",
    "    plt.plot(history['val_loss'],label='Validation',marker='*')\n",
    "#     plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.xticks(np.arange(0,xlim,2))\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "\n",
    "def f_plot_roc_curve(fpr,tpr):\n",
    "    '''\n",
    "    Module for roc plot and printing AUC\n",
    "    '''\n",
    "    plt.figure()\n",
    "    # plt.plot(fpr,tpr)\n",
    "    plt.scatter(fpr,tpr)\n",
    "    plt.semilogx(fpr, tpr)\n",
    "  # Zooms\n",
    "    plt.xlim([10**-7,1.0])\n",
    "    plt.ylim([0,1.0])\n",
    "    # y=x line for comparison\n",
    "    x=np.linspace(0,1,num=500)\n",
    "    plt.plot(x,x)\n",
    "#     plt.xscale('log')\n",
    "#     plt.xlim(1e-10,1e-5)\n",
    "    plt.show()\n",
    "\n",
    "    # AUC \n",
    "    auc_val = auc(fpr, tpr)\n",
    "    print(\"AUC: \",auc_val)\n",
    "\n",
    "\n",
    "def f_plot_fit(inpy,wts,model_dict,model_loc,verbose=True):\n",
    "    '''\n",
    "    Plot fit results.\n",
    "    '''\n",
    "    \n",
    "    model_save_dir=model_loc\n",
    "    model_name=model_dict['name'] # string for the model\n",
    "    fname_model,fname_history='model_{0}.h5'.format(model_name),'history_{0}.pickle'.format(model_name)\n",
    "    \n",
    "        \n",
    "    ########################\n",
    "    ### Read model and history\n",
    "    \n",
    "    ### Check if files exist\n",
    "    assert os.path.exists(model_save_dir+fname_model),\"Model not saved\"\n",
    "    assert os.path.exists(model_save_dir+fname_history),\"History not saved\"\n",
    "    \n",
    "    model=load_model(model_save_dir+fname_model)\n",
    "    with open(model_save_dir+fname_history,'rb') as f:\n",
    "        history= pickle.load(f)\n",
    "    \n",
    "    ########################\n",
    "    if verbose: model.summary()\n",
    "    # Plot tested model\n",
    "    f_plot_learning(history)\n",
    "    \n",
    "    ########################\n",
    "    # Get test predictions\n",
    "    \n",
    "    test_file_name=model_save_dir+'y-predict_model-'+str(model_name)+'.pred'\n",
    "    test_y_file_name=model_save_dir+'y-test_model-'+str(model_name)+'.test'\n",
    "    test_weights_file_name=model_save_dir+'wts-test_model-'+str(model_name)+'.test'    \n",
    "    print(\"Using test prediction from previous test\",test_file_name)\n",
    "\n",
    "    assert os.path.exists(test_file_name),\"y-predictions not saved\"\n",
    "    y_pred=np.loadtxt(test_file_name)\n",
    "    ydata=np.loadtxt(test_y_file_name)\n",
    "    wts=np.loadtxt(test_weights_file_name)\n",
    "    assert(test_y.shape[0]==y_pred.shape[0]),\"Data %s and prediction arrays %s are not of the same size\"%(test_y.shape,y_pred.shape)\n",
    "    \n",
    "    # Condition for the case when the prediction is a 2column array \n",
    "    if len(y_pred.shape)==2: y_pred=y_pred[:,1]\n",
    "    \n",
    "    fpr,tpr,threshold=roc_curve(ydata,y_pred,sample_weight=wts)\n",
    "    print(fpr.shape,tpr.shape,threshold.shape)\n",
    "    f_plot_roc_curve(fpr,tpr)\n",
    "    \n",
    "    model_dict['model'],model_dict['history']=model,history\n",
    "    \n",
    "    return model_dict\n",
    "\n",
    "####################################\n",
    "### Modules for viewing predicted data ###\n",
    "def f_plt_hist(ypred):\n",
    "    ''' Plot a histogram of predictions'''\n",
    "    print(ypred.shape)\n",
    "    plt.figure()\n",
    "    n,bins,patches=plt.hist(ypred, density=None, bins=300)\n",
    "    plt.xlim(0,1)\n",
    "    plt.show()\n",
    "#     plt.close()\n",
    "\n",
    "def f_get_prediction_info(fname,plot=False):\n",
    "    ''' Function that prints info on predicted data.\n",
    "        For example, number of zeroes and ones, plots, etc.\n",
    "        First gathers data from file\n",
    "    '''\n",
    "    \n",
    "    ## Extract predictions\n",
    "    y_pred=np.loadtxt(fname)\n",
    "    # Condition for the case when the prediction is a 2 column array \n",
    "    arr=y_pred[:,1] if len(y_pred.shape)==2 else y_pred\n",
    "    \n",
    "    # Print info and plot\n",
    "    num_total=arr.shape[0]\n",
    "    num_zeros=arr[arr==0.0].shape[0]\n",
    "    num_ones=arr[arr==1.0].shape[0]\n",
    "    print(\"Pred 0's:\\t%s,\\tPred 1's:\\t%s,Total:\\t %s\" %(num_zeros,num_ones,num_total))\n",
    "    if plot:\n",
    "        ### Plot data ###\n",
    "        plt.figure()\n",
    "        plt.plot(arr)\n",
    "        plt.title(\"Prediction\")\n",
    "        plt.show()\n",
    "        \n",
    "        ### Plot histogram ###\n",
    "        f_plt_hist(arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read part of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    \n",
    "    model_loc='/global/project/projectdirs/dasrepo/vpa/ice_cube/data_for_cnn/all_models_Jan28_50epochs/'\n",
    "\n",
    "    ###Extract data : Only extract y-data and weights for tests, which has been saved already along with the model.\n",
    "    ### Note!: the test file data is the same for all models, so just pick the first one. ###\n",
    "#     f1,f2='y-test_model-1.test','wts-test_model-1.test'\n",
    "    f1,f2='y-test_model-15.test','wts-test_model-15.test'\n",
    "\n",
    "    inpy,wts=f_get_ydata_and_wts(model_loc,f1,f2)\n",
    "    test_y,test_wts=inpy[:],wts[:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376302,) (376302,) (376302,) (376302,)\n"
     ]
    }
   ],
   "source": [
    "print(inpy.shape,wts.shape,test_y.shape,test_wts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View predicted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred 0's:\t1064,\tPred 1's:\t341,Total:\t 376302\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768421a5f0a24468bf194b209a9fe656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376302,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896f65e75d4348dbbceeaef9edac2707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fname='/global/project/projectdirs/dasrepo/vpa/ice_cube/data_for_cnn/Jan11_14_models/y-predict_model-1.pred'\n",
    "fname='/global/project/projectdirs/dasrepo/vpa/ice_cube/data_for_cnn/all_models_Jan28_50epochs/y-predict_model-1.pred'\n",
    "\n",
    "f_get_prediction_info(fname,plot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Plot fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 {'name': '15', 'description': None, 'model': None, 'history': None}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1515e8b40caa4c95894d497edbb7c1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using test prediction from previous test /global/project/projectdirs/dasrepo/vpa/ice_cube/data_for_cnn/all_models_Jan28_50epochs/y-predict_model-15.pred\n",
      "(2,) (2,) (2,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1056e2a3c142148b045108e0e58c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.5\n"
     ]
    }
   ],
   "source": [
    "dict_list=[]\n",
    "# for i in range(1,16):\n",
    "for i in [15]:\n",
    "    model_dict={'name':str(i),'description':None,'model':None,'history':None}\n",
    "    print(i,model_dict)\n",
    "    model_dict=f_plot_fit(test_y,test_wts,model_dict,model_loc,verbose=False)\n",
    "    dict_list.append(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Comparing different models:\n",
    "\n",
    "# for md in dict_list:\n",
    "# #     print(md)\n",
    "#     hist=md['history']\n",
    "# #     print(hist)\n",
    "# #     print(md)\n",
    "#     print('Model %s'%(md['name']))\n",
    "#     for key in hist.keys():\n",
    "#         print(key,hist[key])\n",
    "# #     print(md[''])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['a','b','c']\n",
    "dict1=dict.fromkeys(cols,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 10, 'b': 10, 'c': 10}\n"
     ]
    }
   ],
   "source": [
    "print(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "v_py3",
   "language": "python",
   "name": "v_jpt_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
