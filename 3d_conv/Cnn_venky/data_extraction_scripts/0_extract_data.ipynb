{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to extract training and testing data from hdf5 files and storing them in the right form in .npy files\n",
    "\n",
    "The code shuffles data as well.\n",
    "This script gives processed data.\n",
    "Only dependency is util.py\n",
    "- Nov 12, 2018\n",
    "- Nov 27, 2018: Modified to include Hese cuts.\n",
    "- Nov 28, 2018: Inverted condition for Hese cut.\n",
    "- December, 2018: Shuffles data as well.\n",
    "- Feb 5, 2019: Modifed code to work on new data, with new Hese cut.\n",
    "- Feb 19, 2019: Modified code to add a new file storing data info: event_id and filename.\n",
    "- March 11, 2019: Fixed a bug that didn't write the shuffled data to the right files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules from other files\n",
    "from util import add_pulse_to_inp_tensor, get_nonempty_pulses, total_doms, total_height, total_width, get_pulse_array, get_nonempty_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n",
    "- Read in list of .hdf5 files\n",
    "- One by one write data to temp-files in blocks.\n",
    "- Concatenate temp files to get actual data\n",
    "- Extract data into variables.\n",
    "- Format x-data into right shape and save files.\n",
    "- Shuffle data and save files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules to make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def f_make_dataset(filename, sig_or_bg,cut):\n",
    "    '''\n",
    "    Create arrays for xinput, yinput, weights and data_info, from a single file name\n",
    "    This is the function that does the Hese cut.\n",
    "    '''\n",
    "    ####### Modified by Venkitesh, Nov 19, 2018.\n",
    "    try: \n",
    "        hf = h5py.File(filename,'r')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Name of file\",filename)\n",
    "        raise SystemError\n",
    "    \n",
    "    pulse_array_keys = get_nonempty_pulses(hf)\n",
    "    event_array_keys=get_nonempty_events(hf)\n",
    "    # Checking whether the event_array_keys and pulse_array_keys are in order and identical\n",
    "    assert len(pulse_array_keys)==len(event_array_keys), \"Pulse and event array keys have different sizes\"\n",
    "    assert np.array_equal(pulse_array_keys,event_array_keys), \"Pulse array %s and Event array %s are not identical. Possibility of mismatch\"%(pulse_array_keys,event_array_keys)\n",
    "    \n",
    "#     if (sig_or_bg=='sig' and cut=='hese'):\n",
    "    if (cut=='hese'):\n",
    "        key_lst=[] # List that will store the events that satisfy the cuts.\n",
    "        for evt in event_array_keys:\n",
    "            val=hf['events'][evt]\n",
    "            if (val['HESE_flag'][0]!=0): # Not hese event, add to list\n",
    "#                 print(\"Hese-cut\",filename,val['HESE_flag'][0])\n",
    "                key_lst.append(evt)\n",
    "            else: # If hese event, print info and ignore\n",
    "#                 print(\"Filtering Hese_cut\",sig_or_bg,val['HESE_flag'][0],evt,filename)\n",
    "                pass\n",
    "        array_keys=np.array(key_lst)\n",
    "    else: \n",
    "        array_keys=event_array_keys.copy()\n",
    "    \n",
    "    num_events = len(array_keys)\n",
    "    ############################\n",
    "    ### Storing data_info\n",
    "    # creating numpy array with event_id, filename and type:signal or background. This represents an individual event.\n",
    "    info=np.array([np.array([event_id,filename,sig_or_bg]) for event_id in array_keys])\n",
    "    \n",
    "    ### Computing the weights\n",
    "    wgts=np.array([hf['events'][event_key]['weight'][0] for event_key in array_keys])\n",
    "            \n",
    "    tens = np.zeros((num_events, total_doms, total_height, total_width))\n",
    "    for ex_num, pulse_array_key in enumerate(array_keys):\n",
    "        pulse_array = get_pulse_array(hf, pulse_array_key)\n",
    "        add_pulse_to_inp_tensor(tens, ex_num, pulse_array)\n",
    "        \n",
    "    lbls = np.ones((num_events,)) if sig_or_bg == \"sig\" else np.zeros((num_events,))\n",
    "    \n",
    "#     print(info.shape,lbls.shape,wgts.shape,tens.shape)\n",
    "    return tens, lbls, wgts, info\n",
    "\n",
    "\n",
    "def f_get_data(filename_list,file_type,cut):\n",
    "    ''' Code that creates data numpy arrays x,y,wt\n",
    "    file_type=\"sig\" or \"bg\" \n",
    "    '''\n",
    "    \n",
    "    assert (file_type==\"sig\" or file_type==\"bg\"), \"invalid file_type %s: must be sig or bg\"%(file_type)\n",
    "    \n",
    "    count=0 # counter for making an exception for first row of numpy array\n",
    "    for fn in filename_list:\n",
    "        xs,ys,wts,infos = f_make_dataset(fn, file_type,cut)\n",
    "        ### Exception handling for null arrays: If the number of rows is 0-> pass \n",
    "        if xs.shape[0]!=0:\n",
    "            if count==0: # For the first entry, you can't stack, so create first row of numpy arrays. Then append to it.\n",
    "                x,y,wt,info=xs.copy(),ys.copy(),wts.copy(),infos.copy()\n",
    "                count+=1\n",
    "            # For multi-dimensional arrays like x and info, you need np.vstack instead of np.concatenate !\n",
    "            else :\n",
    "                try:\n",
    "                    x = np.vstack((x,xs))\n",
    "                    y = np.concatenate((y,ys))\n",
    "                    wt = np.concatenate((wt,wts))\n",
    "                    info=np.vstack((info,infos))\n",
    "                except Exception as e:\n",
    "                    print(info.shape,infos.shape,x.shape,xs.shape)\n",
    "                    print(fn,file_type)\n",
    "                    print(info,infos)\n",
    "                    raise SystemError\n",
    "#         else: print(\"Null array\")\n",
    "    \n",
    "    return x,y,wt,info\n",
    "\n",
    "def f_shuffle_data(inpx,inpy,wts,info):\n",
    "    ## Shuffle data\n",
    "    \n",
    "    # Setting seed\n",
    "    seed=243\n",
    "    np.random.seed(seed=seed)\n",
    "\n",
    "    size=inpx.shape[0]\n",
    "    ## Get shuffled array of indices\n",
    "    shuffle_arr=np.arange(size)\n",
    "    np.random.shuffle(shuffle_arr)\n",
    "    inpx=inpx[shuffle_arr]\n",
    "    inpy=inpy[shuffle_arr]\n",
    "    wts=wts[shuffle_arr]\n",
    "    info=info[shuffle_arr]\n",
    "    \n",
    "    return inpx,inpy,wts,info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_get_file_lists(data_folder,mode):\n",
    "    ''' Function to the get the list of signal files and background files (sigpath and bgpath) for reserved and training data. \n",
    "        mode='quick' picks a smaller set of files for quick training. These files have the form '*00.hdf5'.\n",
    "        \n",
    "        Arguments:\n",
    "        data_folder='regular' or 'reserved'\n",
    "        mode='normal' or 'quick'\n",
    "    '''\n",
    "    \n",
    "    if data_folder=='reserved':\n",
    "        sigpath = \"/project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/\"\n",
    "        bgpath = \"/global/project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/corsika/11057/\"\n",
    "    elif data_folder=='regular':\n",
    "        sigpath = \"/project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/\"\n",
    "        bgpath = \"/project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/corsika/11057/\"\n",
    "    else : print(\"Invalid option for data_folder\",data_folder); raise SystemError\n",
    "    \n",
    "    # For quick testing, use only the files starting with a '00' at the end ('*00.hdf5'). This give a much smaller set of files, for quick testing.\n",
    "    suffix='*00.hdf5' if mode=='quick' else '*.hdf5'     \n",
    "    sig_list=glob.glob(sigpath+suffix)\n",
    "    bg_list=glob.glob(bgpath+suffix)\n",
    "    \n",
    "    return sig_list,bg_list\n",
    "\n",
    "\n",
    "def f_extract_data(data_folder,save_location,mode,cut):\n",
    "    '''\n",
    "    Function to perform :\n",
    "    - Data read\n",
    "    - Data format\n",
    "    - Data save to file\n",
    "    - Shuffle data\n",
    "    - Save shuffled data\n",
    "    \n",
    "    Arguments:\n",
    "    data_folder='regular' or 'reserved'\n",
    "    save_location= location to save the data files (that are very large)\n",
    "    mode='normal' or 'quick'\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def f_concat_temp_files(count):\n",
    "        ''' Function to concatenate temp files to creat the full file.\n",
    "        Steps:        get data from temp files, stack numpy arrays and delete temp files\n",
    "        '''\n",
    "        \n",
    "        for i in np.arange(count):\n",
    "            prefix='temp_data_%s'%(i)\n",
    "            f1,f2,f3,f4=[prefix+ii+'.npy' for ii in ['_x','_y','_wts','_info']]\n",
    "            xs,ys,wts,infos=np.load(save_location+f1),np.load(save_location+f2),np.load(save_location+f3),np.load(save_location+f4)\n",
    "            \n",
    "            print(xs.shape,i,\"out of \",count)\n",
    "            \n",
    "            if i==0:\n",
    "                x=xs;y=ys;wt=wts;info=infos\n",
    "            else:\n",
    "                x = np.vstack((x,xs))\n",
    "                y = np.concatenate((y,ys))\n",
    "                wt = np.concatenate((wt,wts))\n",
    "                info=np.vstack((info,infos))\n",
    "                \n",
    "            for fname in [f1,f2,f3,f4]: os.remove(save_location+fname) # Delete temp file\n",
    "                \n",
    "        return x,y,wt,info\n",
    "    \n",
    "    ########### Code starts #############\n",
    "    print(\"Type of data:\\t\",data_folder)\n",
    "    \n",
    "    ##########################################\n",
    "    ### Read Data from files ###\n",
    "    sig_list,bg_list=f_get_file_lists(data_folder,mode)\n",
    "    print(\"Sizes of signal and background lists: \",len(sig_list),len(bg_list))\n",
    "    \n",
    "    count=0 # counter for index of temp file \n",
    "    for file_list,sig_or_bg in zip([sig_list,bg_list],['sig','bg']):\n",
    "        print('Type: ',sig_or_bg)\n",
    "        num_files=len(file_list); block_size=100\n",
    "        num_blocks=int(num_files/block_size)+1\n",
    "        print(\"Number of blocks\",num_blocks)\n",
    "        for i in np.arange(num_blocks):\n",
    "            t1=time.time()\n",
    "            start=i*block_size\n",
    "            end=None if i==(num_blocks-1) else (i+1)*block_size # exception handling for last block\n",
    "            \n",
    "            fle_list=file_list[start:end]\n",
    "            inx,inpy,wts,info = f_get_data(fle_list,sig_or_bg,cut)\n",
    "            \n",
    "            ### Save data for each block to temp files ###\n",
    "            prefix='temp_data_%s'%(count)\n",
    "            f1,f2,f3,f4=prefix+'_x',prefix+'_y',prefix+'_wts',prefix+'_info'\n",
    "            for fname,data in zip([f1,f2,f3,f4],[inx,inpy,wts,info]):\n",
    "                np.save(save_location+fname,data)\n",
    "            \n",
    "            count+=1 # count is updated for both signal and bgnd\n",
    "            t2=time.time()\n",
    "            print(\"block number: \",i,\"Start-End\",start,end,\"  time taken in seconds: \",t2-t1)\n",
    "        \n",
    "        print(\"Number of samples after %s: %s \"%(sig_or_bg,inpy.shape[0]))\n",
    "    print(\"Number of temp files written\",count)\n",
    "    \n",
    "    # concatenate files to get full input data files\n",
    "    t1=time.time()\n",
    "    inx,inpy,wts,info=f_concat_temp_files(count)\n",
    "    t2=time.time()\n",
    "    print(\"Time taken for concatenating temp files\",t2-t1)\n",
    "    num=inx.shape[0]\n",
    "    print(\"Data shape after read:\\tx:{0}\\ty:{1}\\twts:{2}\\tinfo:{3}\".format(inx.shape,inpy.shape,wts.shape,info.shape))\n",
    "    \n",
    "    ##########################################\n",
    "    ### Format the x-data for keras 3D CNN ###\n",
    "    inx2=np.expand_dims(inx,axis=1)\n",
    "    inx3=np.transpose(inx2,axes=[0,3,4,2,1])\n",
    "    # print(inx2.shape,inx3.shape)\n",
    "    inpx=inx3.copy()\n",
    "    print(\"Data shape after format:\\tx:{0}\\ty:{1}\".format(inpx.shape,inpy.shape,wts.shape))\n",
    "       \n",
    "    ##########################################\n",
    "    ### Save processed data to files ###\n",
    "    prefix='processed_input_'+data_folder\n",
    "    f1,f2,f3,f4=prefix+'_x',prefix+'_y',prefix+'_wts',prefix+'_info'\n",
    "\n",
    "    for fname,data in zip([f1,f2,f3,f4],[inpx,inpy,wts,info]):\n",
    "        np.save(save_location+fname,data)\n",
    "\n",
    "    ### Shuffle data ###\n",
    "    ix,iy,iwts,iinfo=f_shuffle_data(inpx,inpy,wts,info)\n",
    "    \n",
    "    ### Save shuffled data to files ###\n",
    "    prefix='shuffled_input_'+data_folder\n",
    "    f1,f2,f3,f4=prefix+'_x',prefix+'_y',prefix+'_wts',prefix+'_info'\n",
    "    for fname,data in zip([f1,f2,f3,f4],[ix,iy,iwts,iinfo]):\n",
    "        np.save(save_location+fname,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cut hese\n",
      "Type of data:\t regular\n",
      "Sizes of signal and background lists:  108 85\n",
      "Type:  sig\n",
      "Number of blocks 2\n",
      "Filtering Hese_cut sig 0 nugen_1137415500_55336_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.015500.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137411500_63721_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.011500.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137411500_88955_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.011500.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137411500_97590_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.011500.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137411600_45065_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.011600.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137407300_53107_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.007300.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137407100_91593_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.007100.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137415900_68647_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.015900.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137400900_30723_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.000900.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137408400_13147_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.008400.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137413300_18427_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.013300.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137410700_37200_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.010700.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137410700_4220_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.010700.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137406800_25156_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.006800.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137405500_25442_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.005500.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137405500_75779_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.005500.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137406500_65220_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.006500.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137412200_73392_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.012200.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137412600_19687_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.012600.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137412600_84833_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.012600.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137409200_80917_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.009200.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137413400_7875_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.013400.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137407800_26126_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.007800.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137405700_48904_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.005700.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137407700_11513_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.007700.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137407700_628_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.007700.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137411100_67443_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.011100.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137411100_7945_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.011100.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137408200_87987_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.008200.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137409600_58749_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.009600.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137412300_82644_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.012300.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137412300_92588_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.012300.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137409700_92026_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.009700.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137405300_87805_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.005300.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137407200_39360_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.007200.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137407200_49150_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.007200.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137415100_68255_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.015100.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137410500_2249_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.010500.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137410500_69446_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.010500.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137410500_74572_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.010500.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137407500_40566_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.007500.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137412100_34944_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.012100.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137414800_68154_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.014800.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137411300_41262_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.011300.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137411300_96770_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.011300.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137412400_36314_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.012400.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137408700_55404_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.008700.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137407900_43794_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.007900.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137407900_90083_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.007900.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137413700_20298_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.013700.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137406100_64077_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.006100.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137400400_74051_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.000400.hdf5\n",
      "block number:  0 Start-End 0 100   time taken in seconds:  16.002033710479736\n",
      "Filtering Hese_cut sig 0 nugen_1137409400_13963_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.009400.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137408600_51433_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.008600.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137415300_22152_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.015300.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137409500_26257_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.009500.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137413900_30152_0 /project/projectdirs/dasrepo/icecube_data/hdf5_out/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.013900.hdf5\n",
      "block number:  1 Start-End 100 None   time taken in seconds:  1.2418689727783203\n",
      "Number of samples after sig: 16 \n",
      "Type:  bg\n",
      "Number of blocks 1\n",
      "block number:  0 Start-End 0 None   time taken in seconds:  99.20461058616638\n",
      "Number of samples after bg: 1138 \n",
      "Number of temp files written 3\n",
      "(179, 60, 10, 20) 0 out of  3\n",
      "(16, 60, 10, 20) 1 out of  3\n",
      "(1138, 60, 10, 20) 2 out of  3\n",
      "Time taken for concatenating temp files 0.1465930938720703\n",
      "Data shape after read:\tx:(1333, 60, 10, 20)\ty:(1333,)\twts:(1333,)\tinfo:(1333, 3)\n",
      "Data shape after format:\tx:(1333, 10, 20, 60, 1)\ty:(1333,)\n",
      "Time taken in minutes  1.9505122145016989\n",
      "Type of data:\t reserved\n",
      "Sizes of signal and background lists:  72 564\n",
      "Type:  sig\n",
      "Number of blocks 1\n",
      "Filtering Hese_cut sig 0 nugen_1137417800_16522_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.017800.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137417900_32016_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.017900.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137418400_72580_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.018400.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137401100_64823_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.001100.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137417100_10543_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.017100.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137401600_38651_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.001600.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137418700_92042_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.018700.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137418800_6219_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.018800.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137403900_57976_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.003900.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137403900_75251_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.003900.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137404800_26490_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.004800.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137402800_4265_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.002800.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137416500_99446_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.016500.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137416600_58305_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.016600.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137402900_63114_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.002900.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137402900_90163_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.002900.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137419400_80418_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.019400.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137401700_30025_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.001700.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137402600_96455_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.002600.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137417400_58951_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.017400.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137401900_83565_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.001900.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137419100_80105_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.019100.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137404600_12766_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.004600.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137416400_18827_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.016400.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137402400_18953_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.002400.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137404900_93336_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.004900.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137419600_16722_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.019600.hdf5\n",
      "Filtering Hese_cut sig 0 nugen_1137419600_40534_0 /project/projectdirs/dasrepo/icecube_data/reserved_data/filtered/nugen/11374/clsim-base-4.0.3.0.99_eff/tfilter.Level2_nugen_numu_IC86.2012.011374.019600.hdf5\n",
      "block number:  0 Start-End 0 None   time taken in seconds:  11.5458242893219\n",
      "Number of samples after sig: 140 \n",
      "Type:  bg\n",
      "Number of blocks 6\n",
      "block number:  0 Start-End 0 100   time taken in seconds:  118.36491632461548\n",
      "block number:  1 Start-End 100 200   time taken in seconds:  113.10711002349854\n",
      "block number:  2 Start-End 200 300   time taken in seconds:  115.47197794914246\n",
      "block number:  3 Start-End 300 400   time taken in seconds:  120.09066224098206\n",
      "block number:  4 Start-End 400 500   time taken in seconds:  119.31574249267578\n",
      "block number:  5 Start-End 500 None   time taken in seconds:  77.87394404411316\n",
      "Number of samples after bg: 893 \n",
      "Number of temp files written 7\n",
      "(140, 60, 10, 20) 0 out of  7\n",
      "(1329, 60, 10, 20) 1 out of  7\n",
      "(1267, 60, 10, 20) 2 out of  7\n",
      "(1318, 60, 10, 20) 3 out of  7\n",
      "(1351, 60, 10, 20) 4 out of  7\n",
      "(1313, 60, 10, 20) 5 out of  7\n",
      "(893, 60, 10, 20) 6 out of  7\n",
      "Time taken for concatenating temp files 1.5294990539550781\n",
      "Data shape after read:\tx:(7611, 60, 10, 20)\ty:(7611,)\twts:(7611,)\tinfo:(7611, 3)\n",
      "Data shape after format:\tx:(7611, 10, 20, 60, 1)\ty:(7611,)\n",
      "Time taken in minutes  11.320712117354075\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    data_cut='hese'\n",
    "#     data_cut=None\n",
    "    print(\"Data cut\",data_cut)\n",
    "    \n",
    "    save_data_dir='/global/project/projectdirs/dasrepo/vpa/ice_cube/data_for_cnn/extracted_data_v/data/temp_data/'\n",
    "    \n",
    "    ### Regular data\n",
    "    t1=time.time()\n",
    "    f_extract_data(data_folder='regular',save_location=save_data_dir,mode='normal',cut=data_cut)\n",
    "    t2=time.time()\n",
    "    print(\"Time taken in minutes \",(t2-t1)/60.0)\n",
    "\n",
    "    ### Reserved data ###\n",
    "    t1=time.time()\n",
    "    f_extract_data(data_folder='reserved',save_location=save_data_dir,mode='normal',cut=data_cut)\n",
    "    t2=time.time()\n",
    "    \n",
    "    print(\"Time taken in minutes \",(t2-t1)/60.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 0_extract_data.ipynb to script\n",
      "[NbConvertApp] Writing 12476 bytes to 0_extract_data.py\n"
     ]
    }
   ],
   "source": [
    "# ! jupyter nbconvert --to script 0_extract_data.ipynb\n",
    "# ! mv 0_extract_data.py extract_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "### This is just an estimate for times. \n",
    "\n",
    "The code has changed since Feb 5, 2019\n",
    "Nov 12, 2018\n",
    "\n",
    "Tested this code by doing a diff of regular files with those produced before and they match!\n",
    "Test of times for various stages:\n",
    "\n",
    "#### Regular data:\n",
    "Rough times for each stage in seconds\n",
    "Time for signal      |    2260\n",
    "Time for bg          |  8320\n",
    "Time for extraction  |  323\n",
    "\n",
    "Total time in hours:    2.91 hours\n",
    "\n",
    "#### Reserved data:\n",
    "\n",
    "Rough times for each stage in seconds\n",
    "Time for signal       ||  8588\n",
    "Time for bg           ||  51300\n",
    "Time for extraction   ||  10803\n",
    "\n",
    "Total time in hours:    18.45 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_py3",
   "language": "python",
   "name": "v_jpt_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
